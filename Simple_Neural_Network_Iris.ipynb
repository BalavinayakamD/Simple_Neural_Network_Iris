{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 1.1318365335464478\n",
      "Epoch 10 Loss 0.9658561944961548\n",
      "Epoch 20 Loss 0.6789938807487488\n",
      "Epoch 30 Loss 0.4004894196987152\n",
      "Epoch 40 Loss 0.22509503364562988\n",
      "Epoch 50 Loss 0.12207332998514175\n",
      "Epoch 60 Loss 0.07481689006090164\n",
      "Epoch 70 Loss 0.05451277643442154\n",
      "Epoch 80 Loss 0.04437492415308952\n",
      "Epoch 90 Loss 0.038379427045583725\n",
      "1 tensor([-7.7212,  1.5826,  4.8685]) \t 2 \t 2\n",
      "2 tensor([-10.2316,   0.5146,   8.7767]) \t 2 \t 2\n",
      "3 tensor([-10.7282,   1.1893,   8.2408]) \t 2 \t 2\n",
      "4 tensor([-4.4743,  3.5419, -1.1241]) \t 1 \t 1\n",
      "5 tensor([-9.0954,  1.4687,  6.2899]) \t 2 \t 2\n",
      "6 tensor([-2.2803,  3.7077, -4.1196]) \t 1 \t 1\n",
      "7 tensor([-7.0740,  2.2070,  3.2966]) \t 2 \t 2\n",
      "8 tensor([-4.2271,  3.6553, -1.5467]) \t 1 \t 1\n",
      "9 tensor([-8.0707,  1.8280,  4.7897]) \t 2 \t 2\n",
      "10 tensor([-10.8583,   0.5051,   9.3761]) \t 2 \t 2\n",
      "11 tensor([-6.8676,  2.2165,  3.0859]) \t 2 \t 2\n",
      "12 tensor([  9.4382,   3.2638, -18.8717]) \t 0 \t 0\n",
      "13 tensor([  8.6037,   2.9307, -17.1502]) \t 0 \t 0\n",
      "14 tensor([-1.0594,  3.1702, -4.7116]) \t 1 \t 1\n",
      "15 tensor([  8.0310,   3.2450, -16.7844]) \t 0 \t 0\n",
      "16 tensor([-6.7105,  2.4191,  2.6637]) \t 2 \t 2\n",
      "17 tensor([  8.4678,   3.0888, -17.1317]) \t 0 \t 0\n",
      "18 tensor([-7.6060,  1.7034,  4.5701]) \t 1 \t 2\n",
      "19 tensor([  9.8628,   3.2141, -19.4757]) \t 0 \t 0\n",
      "20 tensor([  7.7276,   2.8980, -15.7355]) \t 0 \t 0\n",
      "21 tensor([-1.6920,  3.3949, -4.3016]) \t 1 \t 1\n",
      "22 tensor([-10.0177,   1.0502,   7.7708]) \t 2 \t 2\n",
      "23 tensor([  8.2674,   3.2234, -17.0561]) \t 0 \t 0\n",
      "24 tensor([  9.2092,   3.0850, -18.2915]) \t 0 \t 0\n",
      "25 tensor([-1.3335,  3.4971, -4.9688]) \t 1 \t 1\n",
      "26 tensor([-2.4308,  3.5983, -3.7124]) \t 1 \t 1\n",
      "27 tensor([-4.7213,  3.5784, -0.9619]) \t 1 \t 1\n",
      "28 tensor([-2.2788,  3.5467, -3.8154]) \t 1 \t 1\n",
      "29 tensor([  9.4498,   3.2186, -18.8342]) \t 0 \t 0\n",
      "30 tensor([-5.0105,  3.2334, -0.1553]) \t 1 \t 1\n",
      "\n",
      "29 out of 30\n",
      "\n",
      "Accuracy: 0.967/1\n",
      "\n",
      "The Given Flower is Iris Setosa\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline uncomment this if you need to see the graph\n",
    "pd.set_option('future.no_silent_downcasting', True) #to remove the future warning\n",
    "\n",
    "class Model(nn.Module):\n",
    "  #Inputs are sepal length, sepal width and petal length, petal width\n",
    "  #There are 2 hidden layers h1 and h2 with 8 datapoints each\n",
    "  #outputs are Iris Setosa , Iris Versicolour , Iris Virginica\n",
    "  def __init__(self,inputFeature = 4,h1 = 8,h2 = 8, outputFeature = 3):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(inputFeature,h1)\n",
    "    self.fc2 = nn.Linear(h1,h2)\n",
    "    self.out = nn.Linear(h2,outputFeature)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.out(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#manually selecting a seed\n",
    "torch.manual_seed(41) #you can also change 41 to random for testing\n",
    "\n",
    "#instance of class Model\n",
    "model = Model()\n",
    "\n",
    "#url of iris dataset csv file by netj from github\n",
    "url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#editing for comfortable processing\n",
    "df['variety'] = df['variety'].replace('Setosa',0.0)\n",
    "df['variety'] = df['variety'].replace('Versicolor',1.0)\n",
    "df['variety'] = df['variety'].replace('Virginica',2.0)\n",
    "\n",
    "# Train Test Split for set X,y\n",
    "X = df.drop( 'variety', axis = 1)\n",
    "y = df['variety'].astype(np.float64) #since typecasting of replace is decrypted\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train, y_test = train_test_split(X , y , test_size= 0.2,random_state= 41) #training is 80% of total size\n",
    "\n",
    "#converting X values to tensor float\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "#converting y values to tensor long\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "#this is for user convinience\n",
    "def chkflwr(x):\n",
    "  if x == 0:\n",
    "    return 'Iris Setosa'\n",
    "  elif x == 1:\n",
    "   return 'Iris Versicolour'\n",
    "  else:\n",
    "    return 'Iris Virginica'\n",
    "#setting the basis of model for entropyloss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#choosing the optimizer (In this case Adam) and learning rate (lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.01)\n",
    "\n",
    "#Model training\n",
    "#set the number of Epochs\n",
    "epochs = 100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "  y_prediction = model.forward(X_train)\n",
    "  loss = criterion(y_prediction,y_train) # y_prediction vs y_train\n",
    "  losses.append(loss.detach().numpy()) #keeping trach od the losses\n",
    "\n",
    "  if i %10 == 0:\n",
    "    print(f'Epoch {i} Loss {loss}')\n",
    "\n",
    "  #backpropogation for optimizing the weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "# You can see the graph for number of epochs vs losses below if needed\n",
    "# plt.plot(range(epochs),losses)\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "\n",
    "# Model training with test data set\n",
    "with torch.no_grad():\n",
    "  y_eval = model.forward(X_test)\n",
    "  loss = criterion(y_eval,y_test)\n",
    "\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "  for i , data in enumerate(X_test):\n",
    "    y_val = model.forward(data)\n",
    "    print(f'{i+1} {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
    "\n",
    "    if y_val.argmax().item() == y_test[i]:\n",
    "      correct += 1\n",
    "print(f'\\n{correct} out of {len(y_test)}')\n",
    "print(f'\\nAccuracy: {round(correct/len(y_test),3)}/1')\n",
    "# save the nn model\n",
    "torch.save(model.state_dict(),'model.pt')\n",
    "#load the model\n",
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load('model.pt',weights_only=False))\n",
    "\n",
    "#Test\n",
    "new_dataPoint = torch.tensor([5.87,3.545,1.234,0.2])\n",
    "with torch.no_grad():\n",
    "  opt = chkflwr(new_model.forward(new_dataPoint).argmax().item())\n",
    "\n",
    "print(f'\\nThe Given Flower is {opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
